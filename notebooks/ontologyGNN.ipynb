{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install obonet\n",
        "!pip install owlready2\n",
        "!pip install rdflib\n",
        "!pip install torch_geometric\n",
        "!pip install PyYAML"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_cVJyY86d0p",
        "outputId": "30e67e24-1630-4f08-9bac-40564cfad35b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: obonet in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from obonet) (3.4.2)\n",
            "Requirement already satisfied: owlready2 in /usr/local/lib/python3.11/dist-packages (0.47)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (7.1.4)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.3)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.train import train_model\n",
        "from src.utils import load_data\n",
        "import torch\n",
        "from torch import nn\n",
        "import argparse\n",
        "import yaml\n",
        "import os"
      ],
      "metadata": {
        "id": "IcqrcRHGHw3F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load config function\n",
        "def load_config(config_path=\"../config.yaml\"):\n",
        "    with open(config_path, \"r\") as f:\n",
        "        return yaml.safe_load(f)"
      ],
      "metadata": {
        "id": "82L42RdiVGjG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# load config\n",
        "config = load_config()\n",
        "\n",
        "data_specs = config['data']\n",
        "data_directory = data_specs['data_directory']\n",
        "\n",
        "# get data\n",
        "train_loader, test_loader, edge_index, ontology_node_list = load_data(\n",
        "        data_directory,\n",
        "        device=device,\n",
        "        batch_size=data_specs['batch_size'],\n",
        "        n_samples=data_specs['n_samples']\n",
        "    )\n",
        "\n",
        "# Train the model\n",
        "print(\"Starting training...\")\n",
        "model, test_losses, modularities = train_model(\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    device=device,\n",
        "    node_list=ontology_node_list,\n",
        "    config=config,\n",
        "    print_stats=True,\n",
        "    plot=True # Set to False if you don't want plots saved\n",
        ")\n",
        "print(\"Training finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcROROAfH7Es",
        "outputId": "06af63ba-20f5-430c-f381-1ba8b6f9f8ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loaded ./data/titanic/titanic_with_cabins.ttl with rdflib (Turtle format)\n",
            "DiGraph with 322 nodes and 853 edges\n",
            "Loaded ./data/titanic/titanic_with_cabins.ttl with rdflib (Turtle format)\n",
            "DiGraph with 322 nodes and 853 edges\n",
            "loaded titanic dataset\n",
            "Starting training...\n",
            "Epoch [10/300], Train Loss: 0.2816, Test Loss: 0.5810 Modularity:  0.35824913\n",
            "Epoch [20/300], Train Loss: 0.2750, Test Loss: 0.5742 Modularity:  0.36040625\n",
            "Epoch [30/300], Train Loss: 0.2706, Test Loss: 0.5721 Modularity:  0.3617345\n",
            "Epoch [40/300], Train Loss: 0.2653, Test Loss: 0.5708 Modularity:  0.36282474\n",
            "Epoch [50/300], Train Loss: 0.2601, Test Loss: 0.5696 Modularity:  0.3638028\n",
            "Epoch [60/300], Train Loss: 0.2548, Test Loss: 0.5682 Modularity:  0.36471194\n",
            "Epoch [70/300], Train Loss: 0.2490, Test Loss: 0.5679 Modularity:  0.36557376\n",
            "Epoch [80/300], Train Loss: 0.2435, Test Loss: 0.5663 Modularity:  0.366396\n",
            "Epoch [90/300], Train Loss: 0.2380, Test Loss: 0.5656 Modularity:  0.36720616\n",
            "Epoch [100/300], Train Loss: 0.2320, Test Loss: 0.5631 Modularity:  0.36823928\n",
            "Epoch [110/300], Train Loss: 0.2248, Test Loss: 0.5629 Modularity:  0.37108496\n",
            "Epoch [120/300], Train Loss: 0.2189, Test Loss: 0.5620 Modularity:  0.37281892\n",
            "Epoch [130/300], Train Loss: 0.2135, Test Loss: 0.5592 Modularity:  0.37372553\n",
            "Epoch [140/300], Train Loss: 0.2089, Test Loss: 0.5583 Modularity:  0.37451243\n",
            "Epoch [150/300], Train Loss: 0.2045, Test Loss: 0.5566 Modularity:  0.37524793\n",
            "Epoch [160/300], Train Loss: 0.2007, Test Loss: 0.5549 Modularity:  0.3759488\n",
            "Epoch [170/300], Train Loss: 0.1967, Test Loss: 0.5535 Modularity:  0.37662584\n",
            "Epoch [180/300], Train Loss: 0.1931, Test Loss: 0.5524 Modularity:  0.37728065\n",
            "Epoch [190/300], Train Loss: 0.1899, Test Loss: 0.5510 Modularity:  0.37792164\n",
            "Epoch [200/300], Train Loss: 0.1866, Test Loss: 0.5494 Modularity:  0.37854475\n",
            "Epoch [210/300], Train Loss: 0.1836, Test Loss: 0.5476 Modularity:  0.379152\n",
            "Epoch [220/300], Train Loss: 0.1807, Test Loss: 0.5466 Modularity:  0.37974513\n",
            "Epoch [230/300], Train Loss: 0.1780, Test Loss: 0.5459 Modularity:  0.38032544\n",
            "Epoch [240/300], Train Loss: 0.1746, Test Loss: 0.5463 Modularity:  0.38089567\n",
            "Epoch [250/300], Train Loss: 0.1711, Test Loss: 0.5494 Modularity:  0.38146353\n",
            "Epoch [260/300], Train Loss: 0.1654, Test Loss: 0.5467 Modularity:  0.38204268\n",
            "Epoch [270/300], Train Loss: 0.1612, Test Loss: 0.5441 Modularity:  0.38265365\n",
            "Epoch [280/300], Train Loss: 0.1581, Test Loss: 0.5483 Modularity:  0.38332343\n",
            "Epoch [290/300], Train Loss: 0.1549, Test Loss: 0.5432 Modularity:  0.3840836\n",
            "Epoch [300/300], Train Loss: 0.1525, Test Loss: 0.5508 Modularity:  0.3848185\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "print(\"\\nEvaluating model performance...\")\n",
        "model.evaluate_model(train_loader, test_loader, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2MkoGcjJjvb",
        "outputId": "ba651d6e-e000-4db2-ba83-65d67411475a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating model performance...\n",
            "Train Accuracy: 0.7500\n",
            "Test Accuracy: 0.7273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze communities\n",
        "print(\"\\nAnalyzing detected communities...\")\n",
        "# Ensure criterion is defined for importance calculation\n",
        "criterion = nn.CrossEntropyLoss().to(device) # Define criterion again if not global or passed\n",
        "\n",
        "print(\"\\nCalculating community importance...\")\n",
        "comm_importance = model.compute_community_importance(\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    device=device,\n",
        "    num_communities=model.num_communities,\n",
        "    print_stats=False # Set to True for detailed output per sample\n",
        ")\n",
        "print(f\"Community Importance (per community): {comm_importance.tolist()}\")\n",
        "most_imp_comm_idx = torch.argmax(comm_importance).item()\n",
        "print(f\"Most important community index: {most_imp_comm_idx}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf1Soi80NmBC",
        "outputId": "2496b2b1-c1a6-4895-d81e-1f79f5479769"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing detected communities...\n",
            "\n",
            "Calculating community importance...\n",
            "Community Importance (per community): [-0.0002778438210953027, 0.000256607832852751, 0.0001695385144557804]\n",
            "Most important community index: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIdentifying important nodes in the most important community...\")\n",
        "important_nodes_freq = model.important_community_nodes(\n",
        "    test_loader,\n",
        "    device=device,\n",
        "    criterion=criterion,\n",
        "    print_stats=False # Set to True for detailed output per sample\n",
        ")\n",
        "\n",
        "# Sort and print top nodes\n",
        "sorted_nodes = sorted(important_nodes_freq.items(), key=lambda item: item[1], reverse=True)\n",
        "print(\"Top nodes in the most important community:\")\n",
        "for node_name, freq in sorted_nodes[:20]: # Print top 20\n",
        "    print(f\"  {node_name}: appears in {freq} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzcuLguXONaA",
        "outputId": "45936440-7e6c-42c9-b100-ca58ca59d4f6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top nodes in the most important community:\n",
            "  A_Deck: appears in 55 samples\n",
            "  A_cabin: appears in 55 samples\n",
            "  AllDisjointClasses: appears in 55 samples\n",
            "  B_Deck: appears in 55 samples\n",
            "  B_cabin: appears in 55 samples\n",
            "  BoatLocation: appears in 55 samples\n",
            "  Boat_Deck: appears in 55 samples\n",
            "  C_Deck: appears in 55 samples\n",
            "  C_cabin: appears in 55 samples\n",
            "  Cabin: appears in 55 samples\n",
            "  Cherbourg: appears in 55 samples\n",
            "  Class: appears in 55 samples\n",
            "  D_Deck: appears in 55 samples\n",
            "  D_cabin: appears in 55 samples\n",
            "  Deck: appears in 55 samples\n",
            "  Distance: appears in 55 samples\n",
            "  E_Deck: appears in 55 samples\n",
            "  E_cabin: appears in 55 samples\n",
            "  Entity: appears in 55 samples\n",
            "  F_Deck: appears in 55 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nIdentifying important edges within the most important community...\")\n",
        "# Assuming edge_index is available from load_data\n",
        "imp_edges = model.important_community_edges(\n",
        "    test_loader,\n",
        "    edge_index=edge_index, # Pass the edge_index\n",
        "    device=device,\n",
        "    criterion=criterion,\n",
        "    print_stats=False # Set to True for detailed output per sample\n",
        ")\n",
        "\n",
        "# Sort and print top edges\n",
        "# Convert edge tuple of indices back to names for printing\n",
        "sorted_edges = sorted(imp_edges.items(), key=lambda item: item[1], reverse=True)\n",
        "print(\"Top edges within the most important community:\")\n",
        "for (i, j), count in sorted_edges[:20]: # Print top 20\n",
        "    name_i = ontology_node_list[i]\n",
        "    name_j = ontology_node_list[j]\n",
        "    print(f\"  ({name_i}, {name_j}): appears in {count} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwXyH-X3OQyl",
        "outputId": "71b7ff8b-7508-4e7c-dde6-a85823c957ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identifying important edges within the most important community...\n",
            "Top edges within the most important community:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Print gradients (useful for debugging training)\n",
        "print(\"\\nPrinting model gradients (last state)...\")\n",
        "model.print_gradients() # Ensure this function is defined in your model or utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XplHFVKAOZXg",
        "outputId": "a2d19193-fe29-4f37-9470-926a7a82b13b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Printing model gradients (last state)...\n",
            "CommunityDetection.conv1.bias: 0.03441854566335678\n",
            "CommunityDetection.conv1.lin.weight: 0.0010838990565389395\n",
            "CommunityDetection.norm.weight: 0.010859488509595394\n",
            "CommunityDetection.norm.bias: 0.011725078336894512\n",
            "OntologyEncoder.conv1.att_src: 0.017874499782919884\n",
            "OntologyEncoder.conv1.att_dst: 2.8556962350378967e-11\n",
            "OntologyEncoder.conv1.bias: 0.06008051708340645\n",
            "OntologyEncoder.conv1.lin.weight: 0.007949931547045708\n",
            "fc2.weight: 0.00857439637184143\n",
            "fc2.bias: 0.027162153273820877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Save the trained model\n",
        "save = config['training']['save_model']\n",
        "\n",
        "if save:\n",
        "    save_dir = config['experiment']['save_dir']\n",
        "    # Create the save directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    save_path = os.path.join(config['experiment']['save_dir'], config['experiment']['name']+'.pt')\n",
        "    # Need to import os\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xZfhBGzN64_",
        "outputId": "e58469ae-7a91-42c0-a360-a255d08f1e3d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to checkpoints/exp1_community_gnn.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PggIbYCxe9f1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}